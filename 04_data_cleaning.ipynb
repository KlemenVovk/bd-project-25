{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 193 parquet files in data/task1/all\n"
     ]
    }
   ],
   "source": [
    "from constants import MAX_SPEED, TASK1_OUT_ROOT, TASK1_SCHEMA, CLEAN_PARQUET_DATA_ROOT, REASONABLE_MAX_TRIP_DURATION, REASONABLE_MAX_YEAR, REASONABLE_MIN_TRIP_DURATION, REASONABLE_MIN_YEAR, REASONABLE_PRICE_MAX, REASONABLE_PRICE_MIN, NYC_MOST_EAST_LONGITUDE, NYC_MOST_WEST_LONGITUDE, NYC_MOST_NORTH_LATITUDE, NYC_MOST_SOUTH_LATITUDE\n",
    "from utils import write_parquet_sequentially\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "parquet_files = sorted(glob(os.path.join(TASK1_OUT_ROOT, \"all\", \"**\", \"*.parquet\")))\n",
    "print(f\"Found {len(parquet_files)} parquet files in {TASK1_OUT_ROOT}/all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5039840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vendor_id', 'pickup_datetime', 'dropoff_datetime', 'passenger_count',\n",
      "       'trip_distance', 'rate_code_id', 'store_and_fwd_flag', 'payment_type',\n",
      "       'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
      "       'improvement_surcharge', 'total_amount', 'congestion_surcharge',\n",
      "       'airport_fee', 'pickup_longitude', 'pickup_latitude',\n",
      "       'dropoff_longitude', 'dropoff_latitude', 'year'],\n",
      "      dtype='object')\n",
      "vendor_id                          int8\n",
      "pickup_datetime          datetime64[ns]\n",
      "dropoff_datetime         datetime64[ns]\n",
      "passenger_count                   uint8\n",
      "trip_distance                   float32\n",
      "rate_code_id                      uint8\n",
      "store_and_fwd_flag                 int8\n",
      "payment_type                      uint8\n",
      "fare_amount                     float32\n",
      "extra                           float32\n",
      "mta_tax                         float32\n",
      "tip_amount                      float32\n",
      "tolls_amount                    float32\n",
      "improvement_surcharge           float32\n",
      "total_amount                    float32\n",
      "congestion_surcharge            float32\n",
      "airport_fee                     float32\n",
      "pickup_longitude                float32\n",
      "pickup_latitude                 float32\n",
      "dropoff_longitude               float32\n",
      "dropoff_latitude                float32\n",
      "year                           category\n",
      "dtype: object\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "dfs = [dd.read_parquet(file) for file in parquet_files]\n",
    "print(dfs[0].columns)\n",
    "print(dfs[0].dtypes)\n",
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37cb4f0",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Filter rows based on:\n",
    "- pickup/dropoff datetimes s.t.:\n",
    "    - pickup is before dropoff at all times\n",
    "    - in case where pickup is a year before the dropoff, we keep the rows where pickup was on the last day of the previous/current year and dropoff was on the first day of the current/next year.\n",
    "- trip distance s.t.:\n",
    "    - is positive\n",
    "    - is within achievable range given 80mph for the given distance and computed trip duration based on dropoff - pickup.\n",
    "= trip duration s.t.:\n",
    "    - is positive (atleast 1min)\n",
    "    - is within generous bounds (1min, 4hours)\n",
    "- pickup/dropoff longitude/latitude\n",
    "    - where either are NaN (not given)\n",
    "    - are in reasonable bounds based on bbox given by: https://www.nyc.gov/assets/planning/download/pdf/data-maps/open-data/meta_nhood.pdf \n",
    "- prices:\n",
    "    - positive for mandatory, nonegative for tips/surcharges\n",
    "    - total_amount has to be atleast equal or larget to the sum of all charges (tips/extras not included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4c91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 32/193 [00:00<00:01, 109.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 62/193 [00:00<00:01, 130.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 92/193 [00:00<00:00, 117.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 123/193 [00:01<00:00, 99.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 155/193 [00:01<00:00, 124.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:01<00:00, 112.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dfs))):\n",
    "    # Pickup/Dropoff datetimes cleaning\n",
    "    dfs[i]['year'] = dfs[i]['pickup_datetime'].dt.year.astype(np.int16)\n",
    "    pickup_before_dropoff = dfs[i]['pickup_datetime'] < dfs[i]['dropoff_datetime']\n",
    "    delta_years = (dfs[i]['dropoff_datetime'].dt.year - dfs[i]['pickup_datetime'].dt.year)\n",
    "    same_year = delta_years == 0\n",
    "    dropoff_next_year = (delta_years == 1) & (dfs[i]['dropoff_datetime'].dt.month == 1) & (dfs[i]['dropoff_datetime'].dt.day == 1) & (dfs[i]['pickup_datetime'].dt.month == 12) & (dfs[i]['pickup_datetime'].dt.day == 31)\n",
    "    reasonable_year = dfs[i]['year'].between(REASONABLE_MIN_YEAR, REASONABLE_MAX_YEAR, inclusive='both')\n",
    "    correct_datetimes = pickup_before_dropoff & (same_year | dropoff_next_year) & reasonable_year\n",
    "\n",
    "    # Trip distance cleaning\n",
    "    trip_duration = (dfs[i]['dropoff_datetime'] - dfs[i]['pickup_datetime']).dt.total_seconds() / (60 * 60) # in hours\n",
    "    achievable_trip_distance = trip_duration * MAX_SPEED\n",
    "    reasonable_trip_duration = trip_duration.between(REASONABLE_MIN_TRIP_DURATION / 60, REASONABLE_MAX_TRIP_DURATION / 60) # in hours\n",
    "    valid_trips = dfs[i]['trip_distance'].between(0, achievable_trip_distance, inclusive='neither') & reasonable_trip_duration\n",
    "\n",
    "    # Coordinates cleaning\n",
    "    latitudes_not_nan = dfs[i]['pickup_latitude'].notnull() & dfs[i]['dropoff_latitude'].notnull()\n",
    "    longitudes_not_nan = dfs[i]['pickup_longitude'].notnull() & dfs[i]['dropoff_longitude'].notnull()\n",
    "    latitudes_within_bounds = (dfs[i]['pickup_latitude'].between(NYC_MOST_SOUTH_LATITUDE, NYC_MOST_NORTH_LATITUDE) & dfs[i]['dropoff_latitude'].between(NYC_MOST_SOUTH_LATITUDE, NYC_MOST_NORTH_LATITUDE))\n",
    "    longitudes_within_bounds = (dfs[i]['pickup_longitude'].between(NYC_MOST_WEST_LONGITUDE, NYC_MOST_EAST_LONGITUDE) & dfs[i]['dropoff_longitude'].between(NYC_MOST_WEST_LONGITUDE, NYC_MOST_EAST_LONGITUDE))\n",
    "    coordinates_reasonable = latitudes_not_nan & longitudes_not_nan & latitudes_within_bounds & longitudes_within_bounds\n",
    "\n",
    "    # Price cleaning\n",
    "    positive_fare = dfs[i]['fare_amount'] > 2.5 # initial charge\n",
    "    nonnegative_extra = dfs[i]['extra'] >= 0\n",
    "    nonnegative_mta = dfs[i]['mta_tax'] >= 0\n",
    "    nonnegative_tip = dfs[i]['tip_amount'] >= 0\n",
    "    nonnegative_tolls = dfs[i]['tolls_amount'] >= 0\n",
    "    nonnegative_improvement = dfs[i]['improvement_surcharge'] >= 0\n",
    "    nonnegative_congestion = dfs[i]['congestion_surcharge'] >= 0\n",
    "    nonnegative_airport_fee = dfs[i]['airport_fee'] >= 0\n",
    "    positive_total = dfs[i]['total_amount'] > 0\n",
    "    reasonable_sum = (\n",
    "        dfs[i]['fare_amount'] +\n",
    "        # dfs[i]['extra'] +\n",
    "        # dfs[i]['tip_amount'] +\n",
    "        dfs[i]['mta_tax'] +\n",
    "        dfs[i]['improvement_surcharge'] +\n",
    "        dfs[i]['tolls_amount'] +\n",
    "        dfs[i]['congestion_surcharge'] +\n",
    "        dfs[i]['airport_fee']).between(0, dfs[i]['total_amount'], inclusive='right')\n",
    "    reasonable_price = dfs[i]['total_amount'].between(REASONABLE_PRICE_MIN, REASONABLE_PRICE_MAX, inclusive='both')\n",
    "    valid_prices = positive_fare & nonnegative_extra & nonnegative_mta & nonnegative_tip & nonnegative_tolls & nonnegative_improvement & nonnegative_congestion & nonnegative_airport_fee & positive_total & reasonable_price & reasonable_sum\n",
    "\n",
    "    # Apply all filters\n",
    "    clean_mask = correct_datetimes & valid_trips & coordinates_reasonable & valid_prices\n",
    "    # display(dfs[i][~clean_mask].head())\n",
    "    dfs[i] = dfs[i][clean_mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1de7ec",
   "metadata": {},
   "source": [
    "## Write the clean dataset to parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9413d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Parquet (all) to data/clean2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/192 [00:23<24:32,  7.79s/it]"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.join(CLEAN_PARQUET_DATA_ROOT), exist_ok=True)\n",
    "# Write parquet (all)\n",
    "print(f\"Writing Parquet (all) to {CLEAN_PARQUET_DATA_ROOT}...\")\n",
    "write_parquet_sequentially(dfs, CLEAN_PARQUET_DATA_ROOT, partition_on=['year'], schema=TASK1_SCHEMA, row_group_size=2000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
